{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functional Requirements - Load Credit Card Database (SQL)\n",
    "\n",
    "Functional Requirement 1.1\n",
    "a)  For “Credit Card System,” create a Python and PySpark SQL\n",
    "    program to read/extract the following JSON files according to the\n",
    "    specifications found in the mapping document.\n",
    "        1. CDW_SAPP_BRANCH.JSON\n",
    "        2. CDW_SAPP_CREDITCARD.JSON\n",
    "        3. CDW_SAPP_CUSTOMER.JSON\n",
    "\n",
    "Note: Data Engineers will be required to transform the data based on the\n",
    "requirements found in the Mapping Document.\n",
    "\n",
    "Hint: [You can use PySQL “select statement query” or simple Pyspark\n",
    "RDD].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Req-1.2 Data loading into Database\n",
    "\n",
    "Function Requirement 1.2\n",
    "Once PySpark reads data from JSON files, and then utilizes Python,\n",
    "PySpark, and Python modules to load data into RDBMS(SQL), perform the\n",
    "following:\n",
    "    a) Create a Database in SQL(MySQL), named “creditcard_capstone.”\n",
    "    b) Create a Python and Pyspark Program to load/write the “Credit\n",
    "    \n",
    "Card System Data” into RDBMS(creditcard_capstone).\n",
    "Tables should be created by the following names in RDBMS:\n",
    "CDW_SAPP_BRANCH\n",
    "CDW_SAPP_CREDIT_CARD\n",
    "CDW_SAPP_CUSTOMER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!! ASK BEN ABOUT THIS STUFF !!!!!!!!\n",
    "\n",
    "\n",
    "What is the difference between Spark session and context?\n",
    "The SparkContext provides methods for creating RDDs, accumulators, and broadcasting variables, as well as methods for starting tasks on the executors. The SparkSession does not provide these methods, but it does provide methods for creating DataFrames and Datasets, as well as methods for reading and writing data.\n",
    "\n",
    "ASK BEN ABOUT THIS STUFF\n",
    "User interface for active sessions\n",
    "\n",
    "from pyspark import SparkContext \n",
    "#this is need to connect to the local host to see the the active session is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+------------+------------+------------+-------------------+----------+--------------------+\n",
      "|      BRANCH_CITY|BRANCH_CODE| BRANCH_NAME|BRANCH_PHONE|BRANCH_STATE|      BRANCH_STREET|BRANCH_ZIP|        LAST_UPDATED|\n",
      "+-----------------+-----------+------------+------------+------------+-------------------+----------+--------------------+\n",
      "|        Lakeville|          1|Example Bank|  1234565276|          MN|       Bridle Court|     55044|2018-04-18T16:51:...|\n",
      "|          Huntley|          2|Example Bank|  1234618993|          IL|  Washington Street|     60142|2018-04-18T16:51:...|\n",
      "|SouthRichmondHill|          3|Example Bank|  1234985926|          NY|      Warren Street|     11419|2018-04-18T16:51:...|\n",
      "|       Middleburg|          4|Example Bank|  1234663064|          FL|   Cleveland Street|     32068|2018-04-18T16:51:...|\n",
      "|    KingOfPrussia|          5|Example Bank|  1234849701|          PA|        14th Street|     19406|2018-04-18T16:51:...|\n",
      "|         Paterson|          7|Example Bank|  1234144890|          NJ|   Jefferson Street|      7501|2018-04-18T16:51:...|\n",
      "|        Pittsford|          8|Example Bank|  1234678272|          NY|           B Street|     14534|2018-04-18T16:51:...|\n",
      "|     Wethersfield|          9|Example Bank|  1234675219|          CT|    Jefferson Court|      6109|2018-04-18T16:51:...|\n",
      "|     NorthOlmsted|         10|Example Bank|  1234145047|          OH|     Cambridge Road|     44070|2018-04-18T16:51:...|\n",
      "|     Hillsborough|         11|Example Bank|  1234366354|          NJ|    3rd Street West|      8844|2018-04-18T16:51:...|\n",
      "|   MadisonHeights|         12|Example Bank|  1234867175|          MI|          Mill Road|     48071|2018-04-18T16:51:...|\n",
      "|           Oviedo|         14|Example Bank|  1234938460|          FL|  Washington Street|     32765|2018-04-18T16:51:...|\n",
      "|    Mechanicsburg|         15|Example Bank|  1234462043|          PA|    Chestnut Street|     17050|2018-04-18T16:51:...|\n",
      "|        Plainview|         16|Example Bank|  1234857525|          NY|       Monroe Drive|     11803|2018-04-18T16:51:...|\n",
      "|          Paducah|         17|Example Bank|  1234546360|          KY|    Railroad Street|     42001|2018-04-18T16:51:...|\n",
      "|     Harleysville|         18|Example Bank|  1234824455|          PA|Church Street South|     19438|2018-04-18T16:51:...|\n",
      "|     SilverSpring|         19|Example Bank|  1234484380|          MD|        King Street|     20901|2018-04-18T16:51:...|\n",
      "|       Burnsville|         20|Example Bank|  1234840138|          MN|   Canterbury Drive|     55337|2018-04-18T16:51:...|\n",
      "|           Tacoma|         21|Example Bank|  1234362433|          WA|         2nd Avenue|     98444|2018-04-18T16:51:...|\n",
      "|         Carlisle|         22|Example Bank|  1234922492|          PA| Front Street South|     17013|2018-04-18T16:51:...|\n",
      "+-----------------+-----------+------------+------------+------------+-------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- BRANCH_CITY: string (nullable = true)\n",
      " |-- BRANCH_CODE: long (nullable = true)\n",
      " |-- BRANCH_NAME: string (nullable = true)\n",
      " |-- BRANCH_PHONE: string (nullable = true)\n",
      " |-- BRANCH_STATE: string (nullable = true)\n",
      " |-- BRANCH_STREET: string (nullable = true)\n",
      " |-- BRANCH_ZIP: long (nullable = true)\n",
      " |-- LAST_UPDATED: string (nullable = true)\n",
      "\n",
      "+-------+-----------+-----------------+------------+--------------------+------------+-------------+------------------+--------------------+\n",
      "|summary|BRANCH_CITY|      BRANCH_CODE| BRANCH_NAME|        BRANCH_PHONE|BRANCH_STATE|BRANCH_STREET|        BRANCH_ZIP|        LAST_UPDATED|\n",
      "+-------+-----------+-----------------+------------+--------------------+------------+-------------+------------------+--------------------+\n",
      "|  count|        115|              115|         115|                 115|         115|          115|               115|                 115|\n",
      "|   mean|       null|76.67826086956522|        null|1.2345499259478261E9|        null|         null|  38975.2347826087|                null|\n",
      "| stddev|       null|52.94113709535237|        null|  258751.74757815443|        null|         null|23938.156819564818|                null|\n",
      "|    min|    Acworth|                1|Example Bank|          1234105725|          AL|  11th Street|              2155|2018-04-18T16:51:...|\n",
      "|    max|   YubaCity|              197|Example Bank|          1234985926|          WI|  York Street|             98908|2018-04-18T16:51:...|\n",
      "+-------+-----------+-----------------+------------+--------------------+------------+-------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sample Code\\nImport pyspark\\nfrom pyspark.sql import SparkSession\\nspark = SparkSession.builder.appName(\\'Sparkappdemo\\').getOrCreate()\\nzipdf = spark.read.json(\"C:/Users/zipcode1.json\")\\nzipdf.createTempView(\"ziptable1\")\\nspark.sql(\"SELECT count(*) from ziptable1\").show\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup for getting ready to Load the database via a Spark Session and sparkSQL\n",
    "# Previously CREATED the \"creditcard_capstone\" DATABASE #\n",
    "# directly within the mySql workbench\n",
    "\n",
    "\n",
    "# Import Setup Environment\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, DoubleType, TimestampType\n",
    "\n",
    "\n",
    "# Loading the JSON file into a spark session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession #Only need one session - Importing the class object SparkSession\n",
    "\n",
    "\n",
    "#### Create an active SparkSession - to be able to utilize \"Spark Dataframes\" (not RDBMS/previously created) ####\n",
    "spark = SparkSession.builder.appName('capstone').getOrCreate() #.builder is the method in the session \n",
    "\n",
    "\n",
    "\n",
    "# ASK BEN ABOUT THIS STUFF\n",
    "# User interface for active sessions\n",
    "# # from pyspark import SparkContext # this is need to connect to the local host to see the the active session is running\n",
    "\n",
    "\n",
    "\n",
    "# Do this at the end of the program - It is good practice to close/stop a session\n",
    "'''spark = SparkSession.stop '''\n",
    "\n",
    "\n",
    "# Setup to read the json file\n",
    "# Both the read and json are methods on the SparkSession object\n",
    "df = spark.read.json(\"C:\\CAPSTONE\\cdw_sapp_branch.json\") \n",
    "\n",
    "\n",
    "#Display data etc. to ensure a sucessful load of json file\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "df.columns\n",
    "\n",
    "\n",
    "'''\n",
    "!!!! ASK BEN ABOUT THIS !!!!\n",
    "# this could cause a problem Just added?\n",
    "spark.sql(\"SELECT count(*) from cdw_sapp_branch.json\").show  '''\n",
    "\n",
    "\n",
    "\n",
    "#SparkSession.getActiveSession() # this will display my active sesson in \"local host 4040\"\n",
    "# http://localhost:4040/jobs/\n",
    "\n",
    "\n",
    "\n",
    "'''Sample Code\n",
    "Import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkappdemo').getOrCreate()\n",
    "zipdf = spark.read.json(\"C:/Users/zipcode1.json\")\n",
    "zipdf.createTempView(\"ziptable1\")\n",
    "spark.sql(\"SELECT count(*) from ziptable1\").show\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-4D6SPVL6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>capstone</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22488bff9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to check and see if the SparkSession is up and running\n",
    "# Code to stop the SparkSession\n",
    "\n",
    "SparkSession.getActiveSession() # this will display my active sesson in \"local host 4040\"\n",
    "# http://localhost:4040/jobs/\n",
    "\n",
    "\n",
    "# Do this at the end of the program - It is good practice to close/stop a session\n",
    "# spark = SparkSession.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, BRANCH_CITY: string, BRANCH_CODE: string, BRANCH_NAME: string, BRANCH_PHONE: string, BRANCH_STATE: string, BRANCH_STREET: string, BRANCH_ZIP: string, LAST_UPDATED: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BRANCH_CODE: integer (nullable = true)\n",
      " |-- BRANCH_NAME: string (nullable = true)\n",
      " |-- BRANCH_STREET: string (nullable = true)\n",
      " |-- BRANCH_CITY: string (nullable = true)\n",
      " |-- BRANCH_STATE: string (nullable = true)\n",
      " |-- BRANCH_ZIP: integer (nullable = true)\n",
      " |-- BRANCH_PHONE: string (nullable = true)\n",
      " |-- LAST_UPDATED: timestamp (nullable = true)\n",
      "\n",
      "+-----------+------------+-----------------+-----------------+------------+----------+-------------+-------------------+\n",
      "|BRANCH_CODE| BRANCH_NAME|    BRANCH_STREET|      BRANCH_CITY|BRANCH_STATE|BRANCH_ZIP| BRANCH_PHONE|       LAST_UPDATED|\n",
      "+-----------+------------+-----------------+-----------------+------------+----------+-------------+-------------------+\n",
      "|          1|Example Bank|     Bridle Court|        Lakeville|          MN|     55044|(123)456-5276|2018-04-18 13:51:47|\n",
      "|          2|Example Bank|Washington Street|          Huntley|          IL|     60142|(123)461-8993|2018-04-18 13:51:47|\n",
      "|          3|Example Bank|    Warren Street|SouthRichmondHill|          NY|     11419|(123)498-5926|2018-04-18 13:51:47|\n",
      "+-----------+------------+-----------------+-----------------+------------+----------+-------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# block of code to load branch data into dbms\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, BooleanType, DoubleType,TimestampType\n",
    "schema = StructType([\n",
    "      StructField(\"BRANCH_CODE\",IntegerType(),True),\n",
    "      StructField(\"BRANCH_NAME\",StringType(),True),\n",
    "      StructField(\"BRANCH_STREET\",StringType(),True),\n",
    "      StructField(\"BRANCH_CITY\",StringType(),True),\n",
    "      StructField(\"BRANCH_STATE\",StringType(),True),\n",
    "      StructField(\"BRANCH_ZIP\",IntegerType(),True),\n",
    "      StructField(\"BRANCH_PHONE\",StringType(),True),\n",
    "      StructField(\"LAST_UPDATED\",TimestampType(),True),\n",
    "  ])\n",
    "\n",
    "df_with_schema = spark.read.schema(schema).json(\"C:\\CAPSTONE\\cdw_sapp_branch.json\")\n",
    "\n",
    "#changing the zipcode if null to transform the data\n",
    "from pyspark.sql.functions import when, col, expr, concat, lit\n",
    "df2= df_with_schema.withColumn(\"BRANCH_ZIP\", when(col(\"BRANCH_ZIP\").isNull(), 99999).otherwise(col(\"BRANCH_ZIP\")))\n",
    "\n",
    "\n",
    "'changing changing the old column branch phone, used concat to match the spec grab from 1 to 3 then grab from 4 for the next three'\n",
    "'this is using the apache spark concat'\n",
    "df3 = df2.withColumn(\n",
    "    \"BRANCH_PHONE\",\n",
    "    concat(\n",
    "        lit(\"(\"),\n",
    "        col(\"BRANCH_PHONE\").substr(1, 3), lit(\")\"),\n",
    "        col(\"BRANCH_PHONE\").substr(4, 3), lit(\"-\"),\n",
    "        col(\"BRANCH_PHONE\").substr(7, 4)\n",
    "    )\n",
    ")\n",
    "\n",
    "df3.printSchema()\n",
    "df3.show(3)\n",
    "\n",
    "\n",
    "\n",
    "df3.write.format(\"jdbc\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "  .option(\"dbtable\", \"CDW_SAPP_BRANCH\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#22222222222\n",
    "SECOND SET OF DATA \"CREDIT CARD\" TO LOAD INTO THE DBMS\n",
    "#22222222222\n",
    "\n",
    "SUNDAY AND MONDAY 10/2\n",
    "insert the credit card spec. directions from the document here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+---+-----+--------------+----------------+-----------------+----+\n",
      "|BRANCH_CODE|  CREDIT_CARD_NO| CUST_SSN|DAY|MONTH|TRANSACTION_ID|TRANSACTION_TYPE|TRANSACTION_VALUE|YEAR|\n",
      "+-----------+----------------+---------+---+-----+--------------+----------------+-----------------+----+\n",
      "|        114|4210653349028689|123459988| 14|    2|             1|       Education|             78.9|2018|\n",
      "|         35|4210653349028689|123459988| 20|    3|             2|   Entertainment|            14.24|2018|\n",
      "|        160|4210653349028689|123459988|  8|    7|             3|         Grocery|             56.7|2018|\n",
      "|        114|4210653349028689|123459988| 19|    4|             4|   Entertainment|            59.73|2018|\n",
      "|         93|4210653349028689|123459988| 10|   10|             5|             Gas|             3.59|2018|\n",
      "|        164|4210653349028689|123459988| 28|    5|             6|       Education|             6.89|2018|\n",
      "|        119|4210653349028689|123459988| 19|    5|             7|   Entertainment|            43.39|2018|\n",
      "|         23|4210653349028689|123459988|  8|    8|             8|             Gas|            95.39|2018|\n",
      "|        166|4210653349028689|123459988| 18|    3|             9|   Entertainment|            93.26|2018|\n",
      "|         83|4210653349028689|123459988|  3|    9|            10|           Bills|           100.38|2018|\n",
      "|         52|4210653349028689|123459988| 21|    8|            11|             Gas|            98.75|2018|\n",
      "|         17|4210653349028689|123459988| 24|   12|            12|             Gas|            42.71|2018|\n",
      "|         80|4210653349028689|123459988|  3|    4|            13|         Grocery|            40.24|2018|\n",
      "|         50|4210653349028689|123459988| 15|    4|            14|           Bills|            17.81|2018|\n",
      "|        123|4210653349028689|123459988| 17|    5|            15|           Bills|             29.0|2018|\n",
      "|          9|4210653349028689|123459988|  6|    7|            16|            Test|            70.63|2018|\n",
      "|          3|4210653349028689|123459988| 28|    9|            17|            Test|            27.04|2018|\n",
      "|        135|4210653349028689|123459988|  4|    7|            18|   Entertainment|            88.75|2018|\n",
      "|        103|4210653349028689|123459988| 24|    4|            19|            Test|            77.02|2018|\n",
      "|         78|4210653349028689|123459988|  8|   10|            20|           Bills|            34.34|2018|\n",
      "+-----------+----------------+---------+---+-----+--------------+----------------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- BRANCH_CODE: long (nullable = true)\n",
      " |-- CREDIT_CARD_NO: string (nullable = true)\n",
      " |-- CUST_SSN: long (nullable = true)\n",
      " |-- DAY: long (nullable = true)\n",
      " |-- MONTH: long (nullable = true)\n",
      " |-- TRANSACTION_ID: long (nullable = true)\n",
      " |-- TRANSACTION_TYPE: string (nullable = true)\n",
      " |-- TRANSACTION_VALUE: double (nullable = true)\n",
      " |-- YEAR: long (nullable = true)\n",
      "\n",
      "+-------+------------------+--------------------+-------------------+-----------------+------------------+------------------+----------------+------------------+--------------------+\n",
      "|summary|       BRANCH_CODE|      CREDIT_CARD_NO|           CUST_SSN|              DAY|             MONTH|    TRANSACTION_ID|TRANSACTION_TYPE| TRANSACTION_VALUE|                YEAR|\n",
      "+-------+------------------+--------------------+-------------------+-----------------+------------------+------------------+----------------+------------------+--------------------+\n",
      "|  count|             46694|               46694|              46694|            46694|             46694|             46694|           46694|             46694|               46694|\n",
      "|   mean| 75.00057823274939|4.210653353368964E15|1.234555184812824E8|14.50736711354778| 6.516875829871076|           23347.5|            null| 51.03938214759932|              2018.0|\n",
      "| stddev|51.389074910957895|2.5604641248039957E7| 2561.2609103365367|8.066305022516385|3.4535079421269828|13479.541071564714|            null|28.783264046884938|1.19216201391582E-13|\n",
      "|    min|                 1|    4210653310061055|          123451007|                1|                 1|                 1|           Bills|              1.01|                2018|\n",
      "|    max|               192|    4210653399939240|          123459988|               28|                12|             46694|            Test|            100.99|                2018|\n",
      "+-------+------------------+--------------------+-------------------+-----------------+------------------+------------------+----------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BRANCH_CODE',\n",
       " 'CREDIT_CARD_NO',\n",
       " 'CUST_SSN',\n",
       " 'DAY',\n",
       " 'MONTH',\n",
       " 'TRANSACTION_ID',\n",
       " 'TRANSACTION_TYPE',\n",
       " 'TRANSACTION_VALUE',\n",
       " 'YEAR']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATA INTO A SPARK SESSION AND TAKE A LOOK AT THE DATA TYPES TO SEE WHAT I HAVE AND IF IT\n",
    "# MATCHES THE INTENDED DATATYPE\n",
    "\n",
    "###### NEED TO FIX THIS \"DAY AND MONTH ARE TOGETHER BUT YEAR IS AT THE END OF THE FILE\"\n",
    "\n",
    "df = spark.read.json(\"C:\\CAPSTONE\\cdw_sapp_credit.json\")\n",
    "\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRANSACTION_ID: integer (nullable = true)\n",
      " |-- BRANCH_CODE: integer (nullable = true)\n",
      " |-- CUST_SSN: integer (nullable = true)\n",
      " |-- TRANSACTION_TYPE: string (nullable = true)\n",
      " |-- TRANSACTION_VALUE: double (nullable = true)\n",
      " |-- CUST_CC_NO: string (nullable = true)\n",
      " |-- TIMEID: string (nullable = true)\n",
      "\n",
      "+--------------+-----------+---------+----------------+-----------------+----------------+--------+\n",
      "|TRANSACTION_ID|BRANCH_CODE| CUST_SSN|TRANSACTION_TYPE|TRANSACTION_VALUE|      CUST_CC_NO|  TIMEID|\n",
      "+--------------+-----------+---------+----------------+-----------------+----------------+--------+\n",
      "|             1|        114|123459988|       Education|             78.9|4210653349028689|20180214|\n",
      "|             2|         35|123459988|   Entertainment|            14.24|4210653349028689|20180320|\n",
      "|             3|        160|123459988|         Grocery|             56.7|4210653349028689|20180708|\n",
      "+--------------+-----------+---------+----------------+-----------------+----------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# block of code to load credit card data into dbms\n",
    "# from pyspark.sql.types import StructType\n",
    "\n",
    "\n",
    "## THIS IS THE ORDER OF THE DATA IN THE JSON FILE MAPPED IT TO THE BELOW ORDER BUT WILL NEED TO FIX THE DATE\n",
    "'''ConnectionAbortedErrorroot\n",
    " |-- BRANCH_CODE: long (nullable = true)\n",
    " |-- CREDIT_CARD_NO: string (nullable = true)\n",
    " |-- CUST_SSN: long (nullable = true)\n",
    " |-- DAY: long (nullable = true)\n",
    " |-- MONTH: long (nullable = true)\n",
    " |-- TRANSACTION_ID: long (nullable = true)\n",
    " |-- TRANSACTION_TYPE: string (nullable = true)\n",
    " |-- TRANSACTION_VALUE: double (nullable = true)\n",
    " |-- YEAR: long (nullable = true)'''\n",
    "\n",
    "schema = StructType([\n",
    "      StructField(\"TRANSACTION_ID\",IntegerType(),True),\n",
    "      StructField(\"BRANCH_CODE\",IntegerType(),True),\n",
    "      StructField(\"CREDIT_CARD_NO\",StringType(),True),\n",
    "      StructField(\"CUST_SSN\",IntegerType(),True), \n",
    "      StructField(\"DAY\",StringType(),True),\n",
    "      StructField(\"MONTH\",StringType(),True),\n",
    "      StructField(\"YEAR\",StringType(),True),\n",
    "      StructField(\"TRANSACTION_TYPE\",StringType(),True),\n",
    "      StructField(\"TRANSACTION_VALUE\",DoubleType(),True)   \n",
    "  ])\n",
    "\n",
    "\n",
    "\n",
    "df_with_schema = spark.read.schema(schema).json(\"C:\\CAPSTONE\\cdw_sapp_credit.json\")\n",
    "\n",
    "#changing the zipcode if null to transform the data\n",
    "#pad the left column below with up to the length of 2 ie from 2 to 02 but if already 10 ie 2 digits does nothing\n",
    "from pyspark.sql.functions import when, col, expr, concat, lit, lpad\n",
    "\n",
    "\n",
    "#########      TO DO LIST      #########\n",
    "\n",
    "# DO THIS FOR EACH COLUMN IN THE MAPPING DOCUMENT THAT HAS A DIFFERENT COLUMN NAME IN THE TARGET TABLE/DBMS COLUMN NAME\n",
    "# FROM THE SOURCE FILE COLUMN NAMES\n",
    "df2= df_with_schema.withColumn(\"CUST_CC_NO\", col(\"CREDIT_CARD_NO\"))\n",
    "\n",
    "df2 = df2.withColumn(\n",
    "    \"TIMEID\",\n",
    "    concat(\n",
    "        col(\"YEAR\"),\n",
    "        lpad(col(\"MONTH\"), 2, \"0\"),\n",
    "        lpad(col(\"DAY\"), 2, \"0\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df2 = df2.drop(\"DAY\", \"MONTH\", \"YEAR\", \"CREDIT_CARD_NO\")\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(3)\n",
    "\n",
    "\n",
    "\n",
    "df2.write.format(\"jdbc\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "  .option(\"dbtable\", \"CDW_SAPP_CREDIT_CARD\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\salom\\OneDrive\\Documents\\PerScholas\\Celia_VSCode\\CAPSTONE\\Load_DB.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# this is to load in the customer data table in the rdbms\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# LOAD DATA INTO A SPARK SESSION AND TAKE A LOOK AT THE DATA TYPES TO SEE WHAT I HAVE AND IF IT\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# MATCHES THE INTENDED DATATYPE\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m###### NEED TO FIX THIS \"DAY AND MONTH ARE TOGETHER BUT YEAR IS AT THE END OF THE FILE\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mjson(\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCAPSTONE\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcdw_sapp_custmer.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salom/OneDrive/Documents/PerScholas/Celia_VSCode/CAPSTONE/Load_DB.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df\u001b[39m.\u001b[39mprintSchema()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# this is to load in the customer data table in the rdbms\n",
    "\n",
    "# LOAD DATA INTO A SPARK SESSION AND TAKE A LOOK AT THE DATA TYPES TO SEE WHAT I HAVE AND IF IT\n",
    "# MATCHES THE INTENDED DATATYPE\n",
    "\n",
    "###### NEED TO FIX THIS \"DAY AND MONTH ARE TOGETHER BUT YEAR IS AT THE END OF THE FILE\"\n",
    "\n",
    "df = spark.read.json(\"C:\\CAPSTONE\\cdw_sapp_custmer.json\")\n",
    "\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SSN: integer (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- MIDDLE_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- CREDIT_CARD_NO: string (nullable = true)\n",
      " |-- CUST_CITY: string (nullable = true)\n",
      " |-- CUST_STATE: string (nullable = true)\n",
      " |-- CUST_COUNTRY: string (nullable = true)\n",
      " |-- CUST_ZIP: integer (nullable = true)\n",
      " |-- CUST_EMAIL: string (nullable = true)\n",
      " |-- LAST_UPDATED: timestamp (nullable = true)\n",
      " |-- CUST_PHONE: string (nullable = true)\n",
      " |-- FULL_STREET_ADDRESS: string (nullable = false)\n",
      "\n",
      "+---------+----------+-----------+---------+----------------+------------+----------+-------------+--------+-------------------+-------------------+----------+--------------------+\n",
      "|      SSN|FIRST_NAME|MIDDLE_NAME|LAST_NAME|  CREDIT_CARD_NO|   CUST_CITY|CUST_STATE| CUST_COUNTRY|CUST_ZIP|         CUST_EMAIL|       LAST_UPDATED|CUST_PHONE| FULL_STREET_ADDRESS|\n",
      "+---------+----------+-----------+---------+----------------+------------+----------+-------------+--------+-------------------+-------------------+----------+--------------------+\n",
      "|123456100|      Alec|         wm|   Hooper|4210653310061055|     Natchez|        MS|United States|   39120|AHooper@example.com|2018-04-21 09:49:02|(123)781-8|Main Street North...|\n",
      "|123453023|      Etta|    brendan|   Holman|4210653310102868|Wethersfield|        CT|United States|    6109|EHolman@example.com|2018-04-21 09:49:02|(123)893-3|  Redwood Drive, 829|\n",
      "|123454487|    Wilber|   ezequiel|   Dunham|4210653310116272|     Huntley|        IL|United States|   60142|WDunham@example.com|2018-04-21 09:49:02|(124)301-8|12th Street East,...|\n",
      "+---------+----------+-----------+---------+----------------+------------+----------+-------------+--------+-------------------+-------------------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# block of code to load credit card data into dbms\n",
    "# from pyspark.sql.types import StructType\n",
    "\n",
    "\n",
    "## THIS IS THE ORDER OF THE DATA IN THE JSON FILE MAPPED IT TO THE BELOW ORDER BUT WILL NEED TO FIX THE DATE\n",
    "\"\"\" root\n",
    " |-- TRANSACTION_ID: integer (nullable = true)\n",
    " |-- BRANCH_CODE: integer (nullable = true)\n",
    " |-- CUST_SSN: integer (nullable = true)\n",
    " |-- TRANSACTION_TYPE: string (nullable = true)\n",
    " |-- TRANSACTION_VALUE: double (nullable = true)\n",
    " |-- CUST_CC_NO: string (nullable = true)\n",
    " |-- TIMEID: string (nullable = true)' \"\"\"\n",
    "\n",
    "schema = StructType([\n",
    "      StructField(\"SSN\",IntegerType(),True),\n",
    "      StructField(\"FIRST_NAME\",StringType(),True),\n",
    "      StructField(\"MIDDLE_NAME\",StringType(),True),\n",
    "      StructField(\"LAST_NAME\",StringType(),True), \n",
    "      StructField(\"CREDIT_CARD_NO\",StringType(),True),\n",
    "      StructField(\"STREET_NAME\",StringType(),True),\n",
    "      StructField(\"APT_NO\",StringType(),True),\n",
    "      StructField(\"CUST_CITY\",StringType(),True),\n",
    "      StructField(\"CUST_STATE\",StringType(),True),\n",
    "      StructField(\"CUST_COUNTRY\",StringType(),True), \n",
    "      StructField(\"CUST_ZIP\",StringType(),True),\n",
    "      StructField(\"CUST_EMAIL\",StringType(),True),\n",
    "      StructField(\"LAST_UPDATED\",TimestampType(),True),\n",
    "      StructField(\"CUST_PHONE\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "\n",
    "\n",
    "df = spark.read.schema(schema).json(\"C:\\CAPSTONE\\cdw_sapp_custmer.json\")\n",
    "\n",
    "#changing the zipcode if null to transform the data\n",
    "#pad the left column below with up to the length of 2 ie from 2 to 02 but if already 10 ie 2 digits does nothing\n",
    "from pyspark.sql.functions import when, col, expr, concat, lit, lpad, lower, initcap, concat_ws\n",
    "\n",
    "\n",
    "#########      TO DO LIST      #########\n",
    "\n",
    "'changing changing the old column branch phone, used concat to match the spec grab from 1 to 3 then grab from 4 for the next three'\n",
    "'this is using the apache spark concat'\n",
    "df = df.withColumn(\n",
    "    \"CUST_PHONE\",\n",
    "    concat(\n",
    "        lit(\"(\"),\n",
    "        col(\"CUST_PHONE\").substr(1, 3), lit(\")\"),\n",
    "        col(\"CUST_PHONE\").substr(4, 3), lit(\"-\"),\n",
    "        col(\"CUST_PHONE\").substr(7, 4))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"FIRST_NAME\", initcap(df[\"FIRST_NAME\"]))\n",
    "df = df.withColumn(\"MIDDLE_NAME\", lower(df[\"MIDDLE_NAME\"]))\n",
    "df = df.withColumn(\"LAST_NAME\", initcap(df[\"LAST_NAME\"]))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"FULL_STREET_ADDRESS\", concat_ws(\", \", df[\"STREET_NAME\"], df[\"APT_NO\"]))\n",
    "\n",
    "df = df.withColumn(\"CUST_ZIP\", col(\"CUST_ZIP\").cast(IntegerType()))\n",
    "\n",
    "df = df.drop(\"STREET_NAME\", \"APT_NO\")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(3)\n",
    "\n",
    "\n",
    "\n",
    "df.write.format(\"jdbc\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "  .option(\"dbtable\", \"CDW_SAPP_CUSTOMER\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|CUST_ZIP|\n",
      "+--------+\n",
      "|   39120|\n",
      "|    6109|\n",
      "|   60142|\n",
      "|   53151|\n",
      "|   79930|\n",
      "|   44070|\n",
      "|   22180|\n",
      "|   91010|\n",
      "|   48867|\n",
      "|   60099|\n",
      "|   44512|\n",
      "|   29483|\n",
      "|   79930|\n",
      "|   48430|\n",
      "|   49418|\n",
      "|   95993|\n",
      "|   33904|\n",
      "|   53045|\n",
      "|   23223|\n",
      "|   19380|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.select(\"CUST_PHONE\").show()\n",
    "df.select(\"CUST_ZIP\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Functional Requirements - Application Front-End\n",
    "Once data is loaded into the database, we need a front-end (console) to see/display data. For that, create a console-based Python program to satisfy System Requirements 2 (2.1 and 2.2).\n",
    "\n",
    "Req-2.1 - Transaction Details Module\n",
    "Functional Requirements 2.1\n",
    "    1) Used to display the transactions made by customers living in a given zip code for a given month and year. Order by day in      descending order.\n",
    "    2) Used to display the number and total values of transactions for a given type.\n",
    "    3) Used to display the total number and total values of transactions for branches in a given state.\n",
    "\n",
    "\n",
    "Req-2.2\t- Customer Details\n",
    "Functional Requirements 2.2\t\n",
    "    1) Used to check the existing account details of a customer.\n",
    "    2) Used to modify the existing account details of a customer.\n",
    "    3) Used to generate a monthly bill for a credit card number for a given month and year.\n",
    "    4) Used to display the transactions made by a customer between two dates. Order by year, month, and day in descending order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERFACE CODE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyspark\n",
    "#from pyspark.sql import SparkSession\n",
    "#spark = SparkSession.builder.master('local[1]').appName('demo.com').getOrCreate()\n",
    "\n",
    "#Need to pick between Transaction details and the customer\n",
    "select=input(\"Choose which details you would like to see\\n\\t1-Transaction\\n\\t2-Customer\\n\")\n",
    "\n",
    "#df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "#    user=\"root\",\\\n",
    "#    password=\"password\",\\\n",
    "#    url=\"jdbc:mysql://localhost:3306/classicmodels\",\\\n",
    "#    dbtable=\"classicmodels.orders\").load()\n",
    "#df.createTempView(\"ziptable1\")\n",
    "#Need zip code, month, and year\n",
    "#spark.sql(\"SELECT count(*) from ziptable1\").show()\n",
    "\n",
    "if select==\"1\": #Transaction\n",
    "    option=input(\"\\n\\n\\n\\nSelect the option you would like to run\\n\\t1-Display the transactions made by \" \n",
    "                 \"customers living in a given zip code for a given month and year\\n\\t2-Display the \" \n",
    "                 \"number and total values of transactions for a given type\\n\\t3-Display the total \"\n",
    "                 \"number and total values of transactions for branches in a given state\\n\")\n",
    "    if option==\"1\":\n",
    "        zip_code=input(\"\\n\\n\\n\\nPlease enter the zip code\\n\")\n",
    "        month=input(\"\\n\\n\\n\\nPlease enter the month as MM\\n\") \n",
    "        year=input(\"\\n\\n\\n\\nPlease enter the year as YYYY\\n\")\n",
    "        #show all transactions made by all customers in this zip code in this month in this year\n",
    "        #order by day in descending order\n",
    "    elif option==\"2\":\n",
    "        #Need the type of transaction\n",
    "        transaction_type=input(\"\\n\\n\\n\\nPlease enter the transaction type\\n\")\n",
    "        #show the total number and total value of these transaction types\n",
    "    elif option==\"3\":\n",
    "        ##Need the state\n",
    "        state=input(\"\\n\\n\\n\\nPlease enter the state's two letter abbreviation (ex. GA)\\n\")\n",
    "        #sum the total number of transactions of the given state and then the total value\n",
    "    else:\n",
    "        print(\"Not an option- Start Over\")\n",
    "        raise\n",
    "        \n",
    "elif select==\"2\": #Customer\n",
    "    option=input(\"\\n\\n\\n\\nSelect the option you would like to run\\n\\t1-Check the existing account details of a customer \" \n",
    "                 \"\\n\\t2-Modify the existing account details of a customer \" \n",
    "                 \"\\n\\t3-Generate a monthly bill for a credit card number for a given month and year \"\n",
    "                 \"\\n\\t4-Display the transactions made by a customer between two dates\\n\")\n",
    "    if option==\"1\": #Need something to identify this customer to show account details\n",
    "        SSn=input(\"\\n\\n\\n\\nPlease enter your SSN\\n\")\n",
    "        #show the account details (probably the row of this SSN)\n",
    "    elif option==\"2\": #To modify the account\n",
    "        SSn=input(\"\\n\\n\\n\\nPlease enter your SSN\\n\")\n",
    "        to_modify=input(\"\\n\\n\\n\\nSelect the option you would like to change\"\n",
    "                \"\\n\\t1-Last Name\"\n",
    "                \"\\n\\t2-Street Address\"\n",
    "                \"\\n\\t3-City\"\n",
    "                \"\\n\\t4-State\"\n",
    "                \"\\n\\t5-Country\"\n",
    "                \"\\n\\t6-Zip Code\"\n",
    "                \"\\n\\t7-Email\"\n",
    "                \"\\n\\t8-Phone\\n\")\n",
    "        if to_modify==\"1\":#last name\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new last name\\n\")\n",
    "            column_name=\"LAST_NAME\"\n",
    "        elif to_modify==\"2\":#street address\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new street address as (Street, Apartment)\\n\")\n",
    "            column_name=\"FULL_STREET_ADDRESS\"\n",
    "        elif to_modify==\"3\": #city\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new city\\n\")\n",
    "            column_name=\"CUST_CITY\"\n",
    "        elif to_modify==\"4\":#state\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new state\\n\")\n",
    "            column_name=\"CUST_STATE\"\n",
    "        elif to_modify==\"5\":#country\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new country\\n\")\n",
    "            column_name=\"CUST_COUNTRY\"\n",
    "        elif to_modify==\"6\":#zip code\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new zip code\\n\")\n",
    "            column_name=\"CUST_ZIP\"\n",
    "        elif to_modify==\"7\":#email\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new email\\n\")\n",
    "            column_name=\"CUST_EMAIL\"\n",
    "        elif to_modify==\"8\":#phone\n",
    "            change_to=input(\"\\n\\n\\n\\nPlease enter your new phone number\\n\")\n",
    "            column_name=\"CUST_PHONE\"\n",
    "        else:\n",
    "            print(\"Not an option- Start Over\")\n",
    "            raise\n",
    "        #Now use the SSN, column_name and the change_to variable to modify the dataframe\n",
    "        \n",
    "    elif option==\"3\": #Generate a monthly bill for a credit card number for a given month/year\n",
    "        CCn=input(\"\\n\\n\\n\\nPlease enter the credit card number\\n\")\n",
    "        month=input(\"\\n\\n\\n\\nPlease enter the month as MM\\n\")\n",
    "        year=input(\"\\n\\n\\n\\nPlease enter the year as YYYY\\n\")\n",
    "        #sum the transaction values for a given CCn and month/year\n",
    "    elif option==\"4\": #Show transactions for a customer between two dates\n",
    "        SSn=input(\"\\n\\n\\n\\nPlease enter your SSN\\n\")\n",
    "        date1=input(\"\\n\\n\\n\\nPlease enter the first date as YYYYMMDD\\n\")\n",
    "        date2=input(\"\\n\\n\\n\\nPlease enter the second date as YYYYMMDD\\n\")\n",
    "        #Order by year, month, and day in descending order\n",
    "    else:\n",
    "        print(\"Not an option- Start Over\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"Not an option- Start Over\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Functional Requirements - Application Front-End\n",
    "Once data is loaded into the database, we need a front-end (console) to see/display data. For that,\n",
    "create a console-based Python program to satisfy System Requirements 2 (2.1 and 2.2).\n",
    "\n",
    "Req-2.1 Transaction Details Module\n",
    "Functional Requirements 2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1) Used to display the transactions made by customers living in a\n",
    "given zip code for a given month and year. Order by day in\n",
    "descending order.\n",
    "\n",
    "!!! THE CUST_ZIP, MONTH, AND YEAR ARE PASSED IN VIA THE INTERFACE!!!\n",
    "SELECT CUST.CUST_ZIP, CREDIT.TIMEID,\n",
    "\tyear(CREDIT.TIMEID) AS YEAR, \n",
    "    month(CREDIT.TIMEID) AS MONTH, \n",
    "    day(CREDIT.TIMEID) AS DAY,\n",
    "    CREDIT.TRANSACTION_ID AS TRANS_ID,\n",
    "    CREDIT.TRANSACTION_TYPE AS TRANS_TYPE,\n",
    "    CREDIT.TRANSACTION_VALUE AS TRANS_VALUE\n",
    "FROM cdw_sapp_customer AS CUST\n",
    "    INNER JOIN cdw_sapp_credit_card AS CREDIT\n",
    "    ON CUST.SSN = CREDIT.cust_SSN\n",
    "WHERE CUST.CUST_ZIP = '1810'\n",
    "    AND CREDIT.timeid = '20181207'\n",
    "ORDER BY DAY Desc\n",
    "!!!! THE CUST_ZIP, MONTH, AND YEAR ARE PASSED IN VIA THE INTERFACE!!!\n",
    "\n",
    "\n",
    "!!! Data Exploration via MySQL for the above query !!!\n",
    "----PRODUCES 15 DISTINCT 4 DIGIT ZIP CODES----\n",
    "USE creditcard_capstone;\n",
    "Select distinct CUST_ZIP from cdw_sapp_customer\n",
    "where length(CUST_ZIP) < 5\n",
    "order by CUST_ZIP\n",
    "\n",
    "----PRODUCES ROWS OF DATA THAT ARE BAD ZIP CODES IE DO NOT EXIST----\n",
    "USE creditcard_capstone;\n",
    "Select distinct * from cdw_sapp_customer\n",
    "where length(CUST_ZIP) < 5\n",
    "order by CUST_ZIP\n",
    "!!! Data Exploration via MySQL for the above query !!!\n",
    "\n",
    "\n",
    "\n",
    "2.1.2) Used to display the number and total values of transactions for a given type.\n",
    "!!! THE TRANSACTION_TYPE IS PASSED IN VIA THE INTERFACE!!!\n",
    "!!!FOR EXAMPLE 'Grocery' Returns \"6549\tGrocery\t$337,051.63\"\n",
    "SELECT  COUNT(*),\n",
    "\t\tTRANSACTION_TYPE,\n",
    "        CONCAT('$', FORMAT(sum(TRANSACTION_value), 2)) AS TotalDollarValue\n",
    "FROM cdw_sapp_credit_card\n",
    "WHERE TRANSACTION_TYPE = 'Grocery'\n",
    "GROUP BY TRANSACTION_TYPE\n",
    "!!! THE TRANSACTION_TYPE IS PASSED IN VIA THE INTERFACE!!!\n",
    "\n",
    "\n",
    "\n",
    "2.1.3) Used to display the total number and total values of transactions for branches in a given state.\n",
    "!!! THE b.BRANCH_STATE IS PASSED IN VIA THE INTERFACE!!!\n",
    "SELECT b.BRANCH_STATE, b.BRANCH_NAME, COUNT(c.TRANSACTION_ID) AS total_transactions, \n",
    "\t   CONCAT('$', format(sum(c.TRANSACTION_value), 2)) AS total_value\n",
    "FROM cdw_sapp_credit_card c\n",
    "JOIN cdw_sapp_branch b ON c.BRANCH_CODE = b.BRANCH_CODE\n",
    "WHERE b.BRANCH_STATE = 'GA'\n",
    "GROUP BY b.BRANCH_STATE, b.BRANCH_NAME\n",
    "ORDER BY total_value DESC;\n",
    "!!! THE b.BRANCH_STATE IS PASSED IN VIA THE INTERFACE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Req-2.2\tCustomer Details\n",
    "Functional Requirements 2.2\t\n",
    "    1) Used to check the existing account details of a customer.\n",
    "2) Used to modify the existing account details of a customer.\n",
    "3) Used to generate a monthly bill for a credit card number for a given month and year.\n",
    "4) Used to display the transactions made by a customer between two dates. Order by year, month, and day in descending order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 - Used to check the existing account details of a customer.\n",
    "\n",
    "SELECT lAST_NAME, CUST_ZIP, SSN, TIMEID, year(TIMEID), month(TIMEID), day(TIMEID) as dayOrder\n",
    "FROM cdw_sapp_customer\n",
    "INNER JOIN cdw_sapp_credit_card\n",
    "ON cdw_sapp_customer.SSN = cdw_sapp_credit_card.cust_SSN\n",
    "WHERE cdw_sapp_customer.CUST_ZIP = '1810'\n",
    "AND cdw_sapp_credit_card.timeid = '20181207'\n",
    "ORDER BY dayOrder Desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
